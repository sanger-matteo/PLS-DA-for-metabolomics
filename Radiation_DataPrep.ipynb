{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pID_Survive:   201\n",
      "pID_Dead   :   49\n",
      "Smp_Survive:   798\n",
      "Smp_Dead   :   191\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# ****************************************************************************\n",
    "#                       DATA ORGANIZATION and FORMATING\n",
    "# ****************************************************************************\n",
    "\n",
    "In this script we organize the radiation datasets: \n",
    " - type-format data that is in unusual type (see dates)\n",
    " - renames and change column order where necessary\n",
    " - remove redundant columns, \n",
    " - ensure that all datasets have the same \"observations\" (measured samples)\n",
    "Finally save them as DataFrame.csv which can then be easily shared across \n",
    "scripts and programming languages\n",
    "\n",
    "# ****************************************************************************\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import nan\n",
    "\n",
    "\n",
    "# ****************************************************************************\n",
    "#              Clinical, Mmetabolites and Lipoproteins tables\n",
    "# ****************************************************************************\n",
    "# Create the major dataframes using the following files:\n",
    "# List of clinical table with features and timepoints\n",
    "# => ClinicalData_Klinisk.csv ------------ [n: 1028] \n",
    "#        Patients list and clinical data  (sheets \"Klinik fra Randi\")\n",
    "#        - (including medications, treatments etc...)\n",
    "# => ClinicalData_Oversikt.csv ----------- [n: 250] \n",
    "#        Sample list of all timepoint measurements (sheet \"Oversikt\")\n",
    "#        - (in theory 5 each patient)\n",
    "# => Lipoproteinene_Combined2.csv -------- [n: 1026]\n",
    "#        Lipoprotein measurements (blood serum)\n",
    "# => Metabolittene_comb_final_clean.csv -- [n: 1028]\n",
    "#        Metabolites measurments (blood serum)\n",
    "\n",
    "# ------ LOAD data-tables ------\n",
    "path_Klinisk  = \"/Users/mattesa/molbreastlab-storage/work/Radiation_study/Matteo/ClinicalData_Klinisk.csv\" \n",
    "path_Oversikt = \"/Users/mattesa/molbreastlab-storage/work/Radiation_study/Matteo/ClinicalData_Oversikt.csv\" \n",
    "path_Lipopro  = \"/Users/mattesa/molbreastlab-storage/work/Radiation_study/Matteo/Lipoproteinene_Combined2.csv\" \n",
    "path_Metabol  = \"/Users/mattesa/molbreastlab-storage/work/Radiation_study/Matteo/Metabolittene_comb_final_clean.csv\" \n",
    "root_path = os.path.dirname(path_Lipopro)\n",
    "             \n",
    "# Load clinical data files, Lipoprotein and Metabolites measurments files \n",
    "# NOTE: There are some redundant columns!\n",
    "CD_klinisk = pd.read_csv( path_Klinisk,  header=1, index_col=False)\n",
    "CD_oversik = pd.read_csv( path_Oversikt, header=0, index_col=False)\n",
    "LP_measure = pd.read_csv( path_Lipopro,  header=0, index_col=False)\n",
    "MB_measure = pd.read_csv( path_Metabol,  header=0, index_col=False)\n",
    "\n",
    "\n",
    "# ------ PRUNING the data ------\n",
    "# Extract the timepoints as defined by Guro. We could also redifine by looking \n",
    "# dates or use dates to find matching measurments between different dataframes \n",
    "sele_oversik  = [ \"PatientID\", \n",
    "                  \"Samplenames lipo\", \"Names date modified\", \"Samling date\", \n",
    "                  \"Dato stråleterapi\", \n",
    "                  \"Timepoint\", \"Timepoint_kodet\",\n",
    "                  \"Alder\", \"BMI\", \n",
    "                  \"HEr2 \", \"ER \", \"PGR\",\"kjemo\", \"herceptin\" , \"hormornbeh\",\n",
    "                  \"FatPAS.1\", \"FatPAS.2\", \"FatPAS.3\", \"FatPAS.4\", \"FatPAS.5\"]\n",
    "CD_samples  = CD_oversik.loc[:,sele_oversik]\n",
    "\n",
    "# Simplify the names of the Metabolites dataframe columns, removing the unit\n",
    "names = MB_measure.columns\n",
    "MB_measure.columns = [xx.split(\" (RawConc)\")[0] for xx in names]\n",
    "\n",
    "# Rename column e.g. \"Samplenames lipo\" in CD_oversik === \"name\" in LP_measure\n",
    "CD_samples = CD_samples.rename(columns={\"Samplenames lipo\": \"Samplename\"})\n",
    "LP_measure = LP_measure.rename(columns={\"name\": \"Samplename\"})\n",
    "MB_measure = MB_measure.rename(columns={\"Sample Name\": \"Samplename\"})\n",
    "CD_samples = CD_samples.rename(columns={\"HEr2 \": \"HER2\"})\n",
    "CD_samples = CD_samples.rename(columns={\"ER \": \"ER\"})\n",
    "\n",
    "# Insert a \"PatientID\" column in LP and MB dataframes (redundant but good practice)\n",
    "pID = [ xx.split(\"_\")[0] for xx in LP_measure[\"Samplename\"]]\n",
    "LP_measure.insert( loc=1, column=\"PatientID\", value=pID)\n",
    "pID = [ xx.split(\"_\")[0] for xx in MB_measure[\"Samplename\"]]\n",
    "MB_measure.insert( loc=1, column=\"PatientID\", value=pID)\n",
    "\n",
    "\n",
    "# ! Ensure that the different DFs (CD, LP and MB) have the exact same set of \n",
    "#   samples in their list. Use \"Samplename\" compare and remove those samples\n",
    "#   that appear only in one dataframe.\n",
    "# NOTE: check manually on the list what we are actually removing !!!\n",
    "#       Specifically, LP have less samples than MP and CD\n",
    "# Use set-difference to find missing samples in LP_measure, then reomve those\n",
    "# from the list. Finally, subset DFs selecting only common samples\n",
    "miss_nn = np.setdiff1d( CD_samples[\"Samplename\"], LP_measure[\"Samplename\"])\n",
    "list_nn = np.setdiff1d( CD_samples[\"Samplename\"], miss_nn )\n",
    "CD_samples = CD_samples.loc[CD_samples[\"Samplename\"].isin(list_nn)]\n",
    "\n",
    "# As above, but between LP_measure and MB_measure\n",
    "# NOTE: MB_measure has repeated measurments for a couple of samples !!!\n",
    "miss_nn = np.setdiff1d( MB_measure[\"Samplename\"], LP_measure[\"Samplename\"])\n",
    "list_nn = np.setdiff1d( MB_measure[\"Samplename\"], miss_nn )\n",
    "MB_measure = MB_measure.loc[MB_measure[\"Samplename\"].isin(list_nn)]\n",
    "\n",
    "# Remove quality control measurments: strings starting with \"QC\"\n",
    "mask_QC = [\"QC\" not in xx   for xx in LP_measure[\"Samplename\"]]\n",
    "CD_samples = CD_samples.loc[ mask_QC, : ]\n",
    "LP_measure = LP_measure.loc[ mask_QC, : ]\n",
    "MB_measure = MB_measure.loc[ mask_QC, : ]\n",
    "\n",
    "\n",
    "# At this point we have the exact same entries in both DataFrames. \n",
    "# (Check by running np.setdiff1d in all combinations between the 3 DFs)\n",
    "# Sort-by name columns \"Samplename\" and then remove uncategorized timepoints.\n",
    "CD_samples = CD_samples.sort_values(\"Samplename\")\n",
    "LP_measure = LP_measure.sort_values(\"Samplename\")\n",
    "MB_measure = MB_measure.sort_values(\"Samplename\")\n",
    "\n",
    "# Correct Syntax errors in Time column ('pre ' (with space) instead of 'pre')\n",
    "idx = CD_samples.index[CD_samples['Timepoint']== 'pre '].tolist()\n",
    "CD_samples.loc[idx] = CD_samples.loc[idx]['Timepoint'] = 'pre'\n",
    "\n",
    "# Remove the samples tagged \"pre\" in HER2 column\n",
    "#mask = np.array(CD_samples[\"PGR\"] == -100)\n",
    "# Remove 'nan' values (CD_samples['Timepoint']== '?')\n",
    "mask = CD_samples[\"Timepoint_kodet\"].isnull().values\n",
    "CD_samples = CD_samples.loc[ ~mask, : ]\n",
    "LP_measure = LP_measure.loc[ ~mask, : ]\n",
    "MB_measure = MB_measure.loc[ ~mask, : ]\n",
    "\n",
    "\n",
    "# ------ REORGANIZE and SORT variables ------\n",
    "# Now all DFs the sample measurements sorted in the same order (Samplename)\n",
    "# Thus, we reindex the rows in all DFs to be the same.\n",
    "CD_samples = CD_samples.reset_index(drop=True)\n",
    "LP_measure = LP_measure.reset_index(drop=True)\n",
    "MB_measure = MB_measure.reset_index(drop=True)\n",
    "\n",
    "# Reorganize the \"covariates\" order so that we remove redundant (colinear) \n",
    "# factors and we can plot them together based on meaningful grouping\n",
    "# and order (e.g. class of molecules)\n",
    "# TG  = tryglyceride\n",
    "# CH  = total cholesterol\n",
    "# FC  = free cholesterol\n",
    "# (EC = esterified cholesterol) \n",
    "# PL  = phosppholipids\n",
    "# AB  = ApoB  (=== particle numbers, for specific class)\n",
    "# A1  = ApoA (only HDL)\n",
    "vars_LP_order = [  \n",
    "                'V1TG', 'V1CH', 'V1FC', 'V1PL', \n",
    "                'V2TG', 'V2CH', 'V2FC', 'V2PL', \n",
    "                'V3TG', 'V3CH', 'V3FC', 'V3PL', \n",
    "                'V4TG', 'V4CH', 'V4FC', 'V4PL', \n",
    "                'V5TG', 'V5CH', 'V5FC', 'V5PL', \n",
    "\n",
    "                'IDTG', 'IDCH', 'IDFC', 'IDPL',\n",
    "\n",
    "                'L1TG', 'L1CH', 'L1FC', 'L1PL',\n",
    "                'L2TG', 'L2CH', 'L2FC', 'L2PL',\n",
    "                'L3TG', 'L3CH', 'L3FC', 'L3PL',\n",
    "                'L4TG', 'L4CH', 'L4FC', 'L4PL',\n",
    "                'L5TG', 'L5CH', 'L5FC', 'L5PL',\n",
    "                'L6TG', 'L6CH', 'L6FC', 'L6PL',\n",
    "\n",
    "                'H1TG', 'H1CH', 'H1FC', 'H1PL', 'H1A1', 'H1A2',\n",
    "                'H2TG', 'H2CH', 'H2FC', 'H2PL', 'H2A1', 'H2A2',\n",
    "                'H3TG', 'H3CH', 'H3FC', 'H3PL', 'H3A1', 'H3A2',\n",
    "                'H4TG', 'H4CH', 'H4FC', 'H4PL', 'H4A1', 'H4A2',\n",
    "                ]\n",
    "vars_MB_order = [ 'Lysine', 'Histidine', 'Glutamic acid',\n",
    "                  'Glutamine', 'Asparagine', 'Threonine', \n",
    "                  'Glycine', 'Proline',\n",
    "                  'Phenylalanine', 'Leucine', 'Alanine', 'Tyrosine', 'Valine', 'Isoleucine', 'Methionine',                  \n",
    "                  'N,N-Dimethylglycine', 'Ornithine', 'Sarcosine',                 \n",
    "                  '2-Hydroxybutyric acid', '3-Hydroxybutyric acid', '2-Oxoglutaric acid', '2-Aminobutyric acid',\n",
    "                  'Pyruvic acid', 'Citric acid', 'Acetic acid', 'Lactic acid', 'Succinic acid', 'Formic acid', 'Acetoacetic acid',                  \n",
    "                  'K-EDTA','Ca-EDTA',                 \n",
    "                  'Acetone', 'Glycerol',                 \n",
    "                  'D-Galactose', 'Glucose',                 \n",
    "                  'Dimethylsulfone',                   \n",
    "                  'Choline', 'Creatine', 'Creatinine'\n",
    "                 ]\n",
    "\n",
    "data = LP_measure.iloc[:,4:]\n",
    "# Simplify the index (covariates) names by removing the \"unit\"\n",
    "names = data.columns.values\n",
    "names = [ xx.split(\" [\")[0] for xx in names]\n",
    "data.columns = names\n",
    "# select and sort on ly the variables in vars_LP_order\n",
    "data = data.loc[:,vars_LP_order] \n",
    "data = data.reindex(vars_LP_order, axis = 1)\n",
    "LP_measure = pd.concat( [LP_measure.iloc[:,0:4], data], axis = 1 )\n",
    "\n",
    "data = MB_measure.iloc[:,2:]\n",
    "data = data.reindex(vars_MB_order, axis = 1)\n",
    "MB_measure = pd.concat( [MB_measure.iloc[:,0:2], data], axis = 1 )\n",
    "\n",
    "\n",
    "# ------ SAVE ------\n",
    "# Save as Python-Ready .csv file\n",
    "CD_samples.to_csv( root_path + \"/PyR_Sample_ClinikData.csv\"  , header=True, index=True)\n",
    "LP_measure.to_csv( root_path + \"/PyR_Lipoproteine.csv\", header=True, index=True)\n",
    "MB_measure.to_csv( root_path + \"/PyR_Metabolittene.csv\", header=True, index=True)\n",
    "\n",
    "\n",
    "\n",
    "# ****************************************************************************\n",
    "#                                Survival data\n",
    "# ****************************************************************************\n",
    "# Create a dataframes using survival file. \n",
    "# => Radiationstudy_survival_modified_MS.xlsx ------------ [n: 250] \n",
    "#        Patients list with survival and follow-up data\n",
    "# Survival data format requires more ad-hoc working; thus we work on it here separately.\n",
    "# NOTE:\n",
    "# Survival state:  1= lever,  2= tilbakefall, 3= kreftdød,     4= annen død \n",
    "#                  1= alive,  2= relapse,     3= cancer death, 4= other death \n",
    "\n",
    "#------ LOAD SURVIVAL data-tables ------\n",
    "# List of patients and importantly the survival. We need to load as .xlsx \n",
    "# because there are \"comment\" columns with \"commas\" that alter the table when \n",
    "# uploaded as .csv file\n",
    "path_Survival = \"/Users/mattesa/molbreastlab-storage/work/Radiation_study/Matteo/Radiationstudy_survival_modified_MS.xlsx\" \n",
    "CD_survival = pd.read_excel( path_Survival,  header=0, index_col=False )\n",
    "\n",
    "# ------ PRUNING the data ------\n",
    "# We exclude columns: \n",
    "# 6 - Komorbidity - a description and requires manual conversion to some categorical data type\n",
    "sele_survival = [ 0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 12]\n",
    "name_conversion = {\"PID\":             \"PatientID\",\n",
    "                   \"Dato start RT\":   \"Date_StartRadio\",\n",
    "                   \"10-års-kontroll lege/siste livstegn\": \"Date_10yCheck\",\n",
    "                   \"QOL-skjema\":           \"Date_QOLquestionnaire\",\n",
    "                   \"Kun QOL\":              \"With_QOL\",\n",
    "                   \"Antall dettatt\":       \"N_Participant\",\n",
    "                   \"Metastase/ ny kreft\":  \"NewCancer\",\n",
    "                   \"Dato mors\":            \"Date_Death\",\n",
    "                   \"Dato tilbakefall\":     \"Date_Relapse\",\n",
    "                   \"Oppfølgingstid\":       \"Followup\",\n",
    "                   \"Status, 1= lever, 2 = tilbakefall, 3 = kreftdød, 4 = annen død\":   \"Status\"\n",
    "                  }\n",
    "CD_survival = CD_survival.iloc[:, sele_survival]\n",
    "CD_survival = CD_survival.rename(columns= name_conversion)\n",
    "\n",
    "# Uniformize the date from strings to datetime64 \n",
    "# NOTE: NAN strings (possibly no follow up due to death) are convered into\n",
    "#       NaT in datetime64. To find NaT use .isnull() method\n",
    "CD_survival[\"Date_StartRadio\"] = pd.to_datetime(CD_survival[\"Date_StartRadio\"], infer_datetime_format=True, errors='coerce')\n",
    "CD_survival[\"Date_10yCheck\"]   = pd.to_datetime(CD_survival[\"Date_10yCheck\"], infer_datetime_format=True, errors='coerce')\n",
    "CD_survival[\"Date_Death\"]      = pd.to_datetime(CD_survival[\"Date_Death\"], infer_datetime_format=True, errors='coerce')\n",
    "CD_survival[\"Date_Relapse\"]    = pd.to_datetime(CD_survival[\"Date_Relapse\"], infer_datetime_format=True, errors='coerce')\n",
    "CD_survival[\"Date_QOLquestionnaire\"] = pd.to_datetime(CD_survival[\"Date_QOLquestionnaire\"], infer_datetime_format=True, errors='coerce')\n",
    "\n",
    "# Replace NaN and convert scolumns into simple 0-1 values\n",
    "mask    = CD_survival[\"N_Participant\"].isnull()\n",
    "CD_survival.loc[mask, \"N_Participant\"] = 0\n",
    "mask    = CD_survival[\"N_Participant\"].isnull()\n",
    "CD_survival.loc[mask, \"N_Participant\"] = 0\n",
    "mask    = CD_survival[\"NewCancer\"].isnull()\n",
    "CD_survival.loc[mask, \"NewCancer\"] = 0\n",
    "\n",
    "\n",
    "# Simplify survival state in binary: 0 deaths of any type; 1 for alive\n",
    "mask_1 = CD_survival[\"Status\"] == 1\n",
    "\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "mask_2 = CD_survival[\"Status\"] >= 2\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "\n",
    "CD_survival.loc[mask_1, \"Status_code\"] = 1\n",
    "CD_survival.loc[mask_2, \"Status_code\"] = 0\n",
    "#mask = CD_survival.loc[:, \"Status_code\"].isnull() \n",
    "\n",
    "# ------ SAVE ------\n",
    "# Save as Python-Ready .csv file\n",
    "CD_survival.to_csv( root_path + \"/PyR_Patients_Survival.csv\" , header=True, index=True)\n",
    "\n",
    "\n",
    "\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# ------ COMBINE ------\n",
    "# Add information about survival in DataFrame CD_samples\n",
    "# Initialize \"0\" column and then, for all alive PatientID replace with \"1\"\n",
    "CD_samples.insert( loc=8, column=\"Status_code\", value=0)\n",
    "mask = CD_survival.loc[:, \"Status_code\"] == 1\n",
    "pIDList = CD_survival.loc[mask, \"PatientID\"].values\n",
    "for ii_patient in pIDList: \n",
    "    CD_samples.loc[ CD_samples.loc[:,\"PatientID\"] == str(ii_patient) , \"Status_code\" ] = 1\n",
    "\n",
    "print(\"pID_Survive:  \", (CD_survival.loc[:, \"Status_code\"] == 1).sum() )\n",
    "print(\"pID_Dead   :  \", (CD_survival.loc[:, \"Status_code\"] == 0).sum() )\n",
    "print(\"Smp_Survive:  \", (CD_samples.loc[:, \"Status_code\"] == 1).sum() )\n",
    "print(\"Smp_Dead   :  \", (CD_samples.loc[:, \"Status_code\"] == 0).sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
