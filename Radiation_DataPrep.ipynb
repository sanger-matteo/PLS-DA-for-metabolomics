{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CD_samples  -  985\n",
      "CD_survival -  985\n",
      "LP_measure  -  985\n",
      "MB_measure  -  985\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# ****************************************************************************\n",
    "#                       DATA ORGANIZATION and FORMATING\n",
    "# ****************************************************************************\n",
    "\n",
    "In this script we organize the radiation datasets: \n",
    " - type-format data that is in unusual type (see dates)\n",
    " - renames and change column order where necessary\n",
    " - remove redundant columns, \n",
    " - ensure that all datasets have the same \"observations\" (measured samples)\n",
    "Finally save them as DataFrame.csv which can then be easily shared across \n",
    "scripts and programming languages\n",
    "\n",
    "# ****************************************************************************\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import nan\n",
    "\n",
    "\n",
    "# ****************************************************************************\n",
    "#              Clinical, Mmetabolites and Lipoproteins tables\n",
    "# ****************************************************************************\n",
    "# Create the major dataframes using the following files:\n",
    "# List of clinical table with features and timepoints\n",
    "# => ClinicalData_Klinisk.csv ------------ [n: 1028] \n",
    "#        Patients list and clinical data  (sheets \"Klinik fra Randi\")\n",
    "#        - (including medications, treatments etc...)\n",
    "# => ClinicalData_Oversikt.csv ----------- [n: 250] \n",
    "#        Sample list of all timepoint measurements (sheet \"Oversikt\")\n",
    "#        - (in theory 5 each patient)\n",
    "# => Lipoproteinene_Combined2.csv -------- [n: 1026]\n",
    "#        Lipoprotein measurements (blood serum)\n",
    "# => Metabolittene_comb_final_clean.csv -- [n: 1028]\n",
    "#        Metabolites measurments (blood serum)\n",
    "\n",
    "# ------ LOAD data-tables ------\n",
    "path_Klinisk  = \"/Users/mattesa/molbreastlab-storage/work/Radiation_study/Matteo/ClinicalData_Klinisk.csv\" \n",
    "path_Oversikt = \"/Users/mattesa/molbreastlab-storage/work/Radiation_study/Matteo/ClinicalData_Oversikt.csv\" \n",
    "path_Lipopro  = \"/Users/mattesa/molbreastlab-storage/work/Radiation_study/Matteo/Lipoproteinene_Combined2.csv\" \n",
    "path_Metabol  = \"/Users/mattesa/molbreastlab-storage/work/Radiation_study/Matteo/Metabolittene_comb_final_clean.csv\" \n",
    "root_path = os.path.dirname(path_Lipopro)\n",
    "             \n",
    "# Load clinical data files, Lipoprotein and Metabolites measurments files \n",
    "# NOTE: There are some redundant columns!\n",
    "CD_klinisk = pd.read_csv( path_Klinisk,  header=1, index_col=False)\n",
    "CD_oversik = pd.read_csv( path_Oversikt, header=0, index_col=False)\n",
    "LP_measure = pd.read_csv( path_Lipopro,  header=0, index_col=False)\n",
    "MB_measure = pd.read_csv( path_Metabol,  header=0, index_col=False)\n",
    "\n",
    "\n",
    "# ------ PRUNING the data ------\n",
    "# Extract the timepoints as defined by Guro. We could also redifine by looking \n",
    "# dates or use dates to find matching measurments between different dataframes \n",
    "sele_oversik  = [ \"Samplenames lipo\", \"Names date modified\", \"Samling date\", \n",
    "                  \"Dato stråleterapi\", \n",
    "                  \"Timepoint\", \"Timepoint_kodet\",\n",
    "                  \"Alder\", \"BMI\", \n",
    "                  \"HEr2 \", \"ER \", \"PGR\",\"kjemo\", \"herceptin\" , \"hormornbeh\",\n",
    "                  \"FatPAS.1\", \"FatPAS.2\", \"FatPAS.3\", \"FatPAS.4\", \"FatPAS.5\"]\n",
    "CD_samples  = CD_oversik.loc[:,sele_oversik]\n",
    "\n",
    "# Simplify the names of the Metabolites dataframe columns, removing the unit\n",
    "names = MB_measure.columns\n",
    "MB_measure.columns = [xx.split(\" (RawConc)\")[0] for xx in names]\n",
    "\n",
    "# Rename column e.g. \"Samplenames lipo\" in CD_oversik === \"name\" in LP_measure\n",
    "CD_samples = CD_samples.rename(columns={\"Samplenames lipo\": \"Samplename\"})\n",
    "LP_measure = LP_measure.rename(columns={\"name\": \"Samplename\"})\n",
    "MB_measure = MB_measure.rename(columns={\"Sample Name\": \"Samplename\"})\n",
    "CD_samples = CD_samples.rename(columns={\"HEr2 \": \"HER2\"})\n",
    "CD_samples = CD_samples.rename(columns={\"ER \": \"ER\"})\n",
    "\n",
    "# Remove quality control measurments: strings starting with \"QC\"\n",
    "mask_QC = [\"QC\" not in xx   for xx in CD_samples[\"Samplename\"]]\n",
    "CD_samples = CD_samples.loc[ mask_QC, : ]\n",
    "mask_QC = [\"QC\" not in xx   for xx in LP_measure[\"Samplename\"]]\n",
    "LP_measure = LP_measure.loc[ mask_QC, : ]\n",
    "mask_QC = [\"QC\" not in xx   for xx in MB_measure[\"Samplename\"]]\n",
    "MB_measure = MB_measure.loc[ mask_QC, : ]\n",
    "\n",
    "# Insert a \"PatientID\" column\n",
    "pID = [ xx.split(\"_\")[0] for xx in CD_samples[\"Samplename\"]]\n",
    "CD_samples.insert( loc=1, column=\"PatientID\", value=pID)\n",
    "pID = [ xx.split(\"_\")[0] for xx in LP_measure[\"Samplename\"]]\n",
    "LP_measure.insert( loc=1, column=\"PatientID\", value=pID)\n",
    "pID = [ xx.split(\"_\")[0] for xx in MB_measure[\"Samplename\"]]\n",
    "MB_measure.insert( loc=1, column=\"PatientID\", value=pID)\n",
    "\n",
    "\n",
    "# ! Ensure that the different DFs (CD, LP and MB) have the exact same set of \n",
    "#   samples in their list. Use \"Samplename\" compare and remove those samples\n",
    "#   that appear only in one dataframe.\n",
    "# NOTE: check manually on the list what we are actually removing !!!\n",
    "#       Specifically, LP have less samples than MP and CD\n",
    "# Use set-difference to find missing samples in LP_measure, then reomve those\n",
    "# from the list. Finally, subset DFs selecting only common samples\n",
    "miss_aa = np.setdiff1d( CD_samples[\"Samplename\"], LP_measure[\"Samplename\"])\n",
    "miss_bb = np.setdiff1d( MB_measure[\"Samplename\"], LP_measure[\"Samplename\"])\n",
    "miss_cc = np.setdiff1d( LP_measure[\"Samplename\"], CD_samples[\"Samplename\"])\n",
    "miss_nn = miss_aa.tolist() + miss_bb.tolist() + miss_cc.tolist()  \n",
    "list_nn = np.setdiff1d( CD_samples[\"Samplename\"], miss_nn )\n",
    "CD_samples = CD_samples.loc[CD_samples[\"Samplename\"].isin(list_nn)]\n",
    "list_nn = np.setdiff1d( MB_measure[\"Samplename\"], miss_nn )\n",
    "MB_measure = MB_measure.loc[MB_measure[\"Samplename\"].isin(list_nn)]\n",
    "list_nn = np.setdiff1d( LP_measure[\"Samplename\"], miss_nn )\n",
    "LP_measure = LP_measure.loc[LP_measure[\"Samplename\"].isin(list_nn)]\n",
    "\n",
    "\n",
    "# At this point we have the exact same entries in both DataFrames. \n",
    "# (Check by running np.setdiff1d in all combinations between the 3 DFs)\n",
    "# Sort-by name columns \"Samplename\" and then remove uncategorized timepoints.\n",
    "CD_samples = CD_samples.sort_values(\"Samplename\")\n",
    "LP_measure = LP_measure.sort_values(\"Samplename\")\n",
    "MB_measure = MB_measure.sort_values(\"Samplename\")\n",
    "\n",
    "# Correct Syntax errors in Time column ('pre ' (with space) instead of 'pre')\n",
    "# idx = CD_samples.index[CD_samples['Timepoint']== 'pre '].tolist()\n",
    "# CD_samples.loc[idx] = CD_samples.loc[idx]['Timepoint'] = 'pre'\n",
    "\n",
    "# Remove the samples tagged \"pre\" in HER2 column\n",
    "#mask = np.array(CD_samples[\"PGR\"] == -100)\n",
    "# Remove 'nan' values (CD_samples['Timepoint']== '?')\n",
    "mask = CD_samples[\"Timepoint_kodet\"].isnull().values\n",
    "CD_samples = CD_samples.loc[ ~mask, : ]\n",
    "LP_measure = LP_measure.loc[ ~mask, : ]\n",
    "MB_measure = MB_measure.loc[ ~mask, : ]\n",
    "\n",
    "\n",
    "# ------ REORGANIZE and SORT variables ------\n",
    "# Now all DFs the sample measurements sorted in the same order (Samplename)\n",
    "# Thus, we reindex the rows in all DFs to be the same.\n",
    "CD_samples = CD_samples.reset_index(drop=True)\n",
    "LP_measure = LP_measure.reset_index(drop=True)\n",
    "MB_measure = MB_measure.reset_index(drop=True)\n",
    "\n",
    "# Reorganize the \"covariates\" order so that we remove redundant (colinear) \n",
    "# factors and we can plot them together based on meaningful grouping\n",
    "# and order (e.g. class of molecules)\n",
    "# TG  = tryglyceride\n",
    "# CH  = total cholesterol\n",
    "# FC  = free cholesterol\n",
    "# (EC = esterified cholesterol) \n",
    "# PL  = phosppholipids\n",
    "# AB  = ApoB  (=== particle numbers, for specific class)\n",
    "# A1  = ApoA (only HDL)\n",
    "remove_LP_vars = [\n",
    "                  \"LDHD\", \"ABA1\", \"TBPN\", \"VLPN\", \"IDPN\", \"LDPN\",\n",
    "                  \"L1PN\", \"L2PN\", \"L3PN\", \"L4PN\", \"L5PN\", \"L6PN\"\n",
    "                  ]\n",
    "\n",
    "vars_LP_order = [  \n",
    "                'V1TG', 'V1CH', 'V1FC', 'V1PL', \n",
    "                'V2TG', 'V2CH', 'V2FC', 'V2PL', \n",
    "                'V3TG', 'V3CH', 'V3FC', 'V3PL', \n",
    "                'V4TG', 'V4CH', 'V4FC', 'V4PL', \n",
    "                'V5TG', 'V5CH', 'V5FC', 'V5PL', \n",
    "\n",
    "                'IDTG', 'IDCH', 'IDFC', 'IDPL',\n",
    "\n",
    "                'L1TG', 'L1CH', 'L1FC', 'L1PL',\n",
    "                'L2TG', 'L2CH', 'L2FC', 'L2PL',\n",
    "                'L3TG', 'L3CH', 'L3FC', 'L3PL',\n",
    "                'L4TG', 'L4CH', 'L4FC', 'L4PL',\n",
    "                'L5TG', 'L5CH', 'L5FC', 'L5PL',\n",
    "                'L6TG', 'L6CH', 'L6FC', 'L6PL',\n",
    "\n",
    "                'H1TG', 'H1CH', 'H1FC', 'H1PL', 'H1A1', 'H1A2',\n",
    "                'H2TG', 'H2CH', 'H2FC', 'H2PL', 'H2A1', 'H2A2',\n",
    "                'H3TG', 'H3CH', 'H3FC', 'H3PL', 'H3A1', 'H3A2',\n",
    "                'H4TG', 'H4CH', 'H4FC', 'H4PL', 'H4A1', 'H4A2',\n",
    "                ]\n",
    "vars_MB_order = [ 'Lysine', 'Histidine', 'Glutamic acid',\n",
    "                  'Glutamine', 'Asparagine', 'Threonine', \n",
    "                  'Glycine', 'Proline',\n",
    "                  'Phenylalanine', 'Leucine', 'Alanine', 'Tyrosine', 'Valine', 'Isoleucine', 'Methionine',                  \n",
    "                  'N,N-Dimethylglycine', 'Ornithine', 'Sarcosine',                 \n",
    "                  '2-Hydroxybutyric acid', '3-Hydroxybutyric acid', '2-Oxoglutaric acid', '2-Aminobutyric acid',\n",
    "                  'Pyruvic acid', 'Citric acid', 'Acetic acid', 'Lactic acid', 'Succinic acid', 'Formic acid', 'Acetoacetic acid',                  \n",
    "                  'K-EDTA','Ca-EDTA',                 \n",
    "                  'Acetone', 'Glycerol',                 \n",
    "                  'D-Galactose', 'Glucose',                 \n",
    "                  'Dimethylsulfone',                   \n",
    "                  'Choline', 'Creatine', 'Creatinine'\n",
    "                 ]\n",
    "\n",
    "data = LP_measure.iloc[:,4:]\n",
    "# Simplify the index (covariates) names by removing the \"unit\"\n",
    "names = data.columns.values\n",
    "names = [ xx.split(\" [\")[0] for xx in names]\n",
    "data.columns = names\n",
    "data = data.drop(remove_LP_vars, axis = 1)\n",
    "LP_measure = pd.concat( [LP_measure.iloc[:,0:4], data], axis = 1 )\n",
    "\n",
    "# select and sort only the variables in vars_LP_order\n",
    "#data = data.loc[:,vars_LP_order] \n",
    "#data = data.reindex(vars_LP_order, axis = 1)\n",
    "\n",
    "data = MB_measure.iloc[:,2:]\n",
    "data = data.reindex(vars_MB_order, axis = 1)\n",
    "MB_measure = pd.concat( [MB_measure.iloc[:,0:2], data], axis = 1 )\n",
    "\n",
    "# Quick check to ensure that \"Samplename\" in all three dataframe are in the \n",
    "# same ordered list\n",
    "'''\n",
    "colname = \"Samplename\"\n",
    "DF = pd.DataFrame(data =[ CD_samples[colname],  LP_measure[colname],  MB_measure[colname]]).T\n",
    "DF.columns = [\"CD_samples\", \"LP_measure\", \"MB_measure\"]\n",
    "DF[\"TF\"] = 0\n",
    "for ii in range(len(DF)):\n",
    "    lst = DF.iloc[ii,:-1].values.tolist()\n",
    "    res = all(ele == lst[0] for ele in lst)\n",
    "    DF.iloc[ii,3] = res    \n",
    "DF.loc[DF[\"TF\"]==False, :]\n",
    "'''\n",
    "\n",
    "# ------ SAVE ------\n",
    "# Save as Python-Ready .csv file\n",
    "CD_samples.to_csv( root_path + \"/PyDF_Sample_ClinikData.csv\"  , header=True, index=False)\n",
    "LP_measure.to_csv( root_path + \"/PyDF_Lipoproteine.csv\", header=True, index=False)\n",
    "MB_measure.to_csv( root_path + \"/PyDF_Metabolittene.csv\", header=True, index=False)\n",
    "\n",
    "\n",
    "\n",
    "# ****************************************************************************\n",
    "#                                Survival data\n",
    "# ****************************************************************************\n",
    "# Create a dataframes using survival file. \n",
    "# => Radiationstudy_survival_modified_MS.xlsx ------------ [n: 250] \n",
    "#        Patients list with survival and follow-up data\n",
    "# Survival data format requires more ad-hoc working; thus we work on it here separately.\n",
    "# NOTE:\n",
    "# Survival state:  1= lever,  2= tilbakefall, 3= kreftdød,     4= annen død \n",
    "#                  1= alive,  2= relapse,     3= cancer death, 4= other death \n",
    "\n",
    "#------ LOAD SURVIVAL data-tables ------\n",
    "# List of patients and importantly the survival. We need to load as .xlsx \n",
    "# because there are \"comment\" columns with \"commas\" that alter the table when \n",
    "# uploaded as .csv file\n",
    "path_Survival = \"/Users/mattesa/molbreastlab-storage/work/Radiation_study/Matteo/Radiationstudy_survival_modified_MS.xlsx\" \n",
    "CD_survival = pd.read_excel( path_Survival,  header=0, index_col=False )\n",
    "\n",
    "# ------ PRUNING the data ------\n",
    "# We could exclude columns: \n",
    "# 6 - Komorbidity - a description and requires manual conversion to some categorical data type\n",
    "CD_survival = CD_survival.iloc[:, 0:22]\n",
    "CD_survival['PatientID'] = CD_survival['PatientID'].astype(str)\n",
    "\n",
    "# Uniformize the date from strings to datetime64 \n",
    "# NOTE: NAN strings (possibly no follow up due to death) are convered into\n",
    "#       NaT in datetime64. To find NaT use .isnull() method\n",
    "CD_survival[\"Date_StartRadio\"] = pd.to_datetime(CD_survival[\"Date_StartRadio\"], infer_datetime_format=True, errors='coerce')\n",
    "CD_survival[\"Date_10yCheck\"]   = pd.to_datetime(CD_survival[\"Date_10yCheck\"], infer_datetime_format=True, errors='coerce')\n",
    "CD_survival[\"Date_Death\"]      = pd.to_datetime(CD_survival[\"Date_Death\"], infer_datetime_format=True, errors='coerce')\n",
    "CD_survival[\"Date_Relapse\"]    = pd.to_datetime(CD_survival[\"Date_Relapse\"], infer_datetime_format=True, errors='coerce')\n",
    "CD_survival[\"Date_QOLquestionnaire\"] = pd.to_datetime(CD_survival[\"Date_QOLquestionnaire\"], infer_datetime_format=True, errors='coerce')\n",
    "\n",
    "# Replace NaN and convert columns into simple 0-1 values\n",
    "mask    = CD_survival[\"N_Participant\"].isnull()\n",
    "CD_survival.loc[mask, \"N_Participant\"] = 0\n",
    "mask    = CD_survival[\"N_Participant\"].isnull()\n",
    "CD_survival.loc[mask, \"N_Participant\"] = 0\n",
    "mask    = CD_survival[\"NewCancer\"].isnull()\n",
    "CD_survival.loc[mask, \"NewCancer\"] = 0\n",
    "\n",
    "\n",
    "# ------ SAVE ------\n",
    "# Save as Python-Ready .csv file\n",
    "CD_survival.to_csv( root_path + \"/PyDF_Patients_Survival.csv\" , header=True, index=False)\n",
    "\n",
    "\n",
    "\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# ------ COMBINE survival data into with CD_samples ------\n",
    "\n",
    "Surv_Colns = [  \"Death_All_5y\", \"Death_All_7y\", \"Death_All_10y\", \n",
    "                \"Death_Recur_5y\", \"Death_Recur_7y\", \"Death_Recur_10y\", \n",
    "                \"BC_Death_Recur_5y\", \"BC_Death_Recur_7y\", \"BC_Death_Recur_10y\"\n",
    "             ]\n",
    "# Initialize empty columns\n",
    "for dd in Surv_Colns:\n",
    "    CD_samples[dd] = 9\n",
    "\n",
    "# Add one by one survival data to each row of CD_sample, based on PatientID\n",
    "for dd in Surv_Colns:\n",
    "    for cc in CD_samples.index.values:        \n",
    "        cc_patient = CD_samples.loc[cc, \"PatientID\"]\n",
    "        # Consider that some may be \"nan\" elements\n",
    "        if len( CD_survival.loc[ CD_survival.loc[:,\"PatientID\"] == cc_patient, dd] ) == 0 : \n",
    "            S_value = nan\n",
    "        else :\n",
    "            S_value = CD_survival.loc[ CD_survival.loc[:,\"PatientID\"] == cc_patient, dd].values[0]        \n",
    "        CD_samples.loc[ cc , dd ] = S_value\n",
    "# Display and check that it was succesful\n",
    "#CD_survival.loc[ CD_survival.loc[:,\"Death_Recur_10y\"] == 1, \"PatientID\"].unique()\n",
    "#CD_samples.loc[  CD_samples.loc[:,\"Death_Recur_10y\"] == 1, \"PatientID\"].unique()\n",
    "\n",
    "\n",
    "# ------ SAVE ------\n",
    "# Save updated CD_samples .csv file\n",
    "CD_samples.to_csv( root_path + \"/PyDF_Sample_ClinikData.csv\"  , header=True, index=False)\n",
    "\n",
    "\n",
    "\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "print( \"CD_samples  - \", len(CD_samples))\n",
    "print( \"CD_survival - \", len(CD_samples))\n",
    "print( \"LP_measure  - \", len(CD_samples))\n",
    "print( \"MB_measure  - \", len(CD_samples))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the variables names and colors based on the data_type used for the model\n",
    "data_type = \"LP\"\n",
    "if  data_type == \"LP\":\n",
    "    vars_order = [  \n",
    "                    'V1TG', 'V1CH', 'V1FC', 'V1PL', \n",
    "                    'V2TG', 'V2CH', 'V2FC', 'V2PL', \n",
    "                    'V3TG', 'V3CH', 'V3FC', 'V3PL', \n",
    "                    'V4TG', 'V4CH', 'V4FC', 'V4PL', \n",
    "                    'V5TG', 'V5CH', 'V5FC', 'V5PL', \n",
    "\n",
    "                    'IDTG', 'IDCH', 'IDFC', 'IDPL',\n",
    "\n",
    "                    'L1TG', 'L1CH', 'L1FC', 'L1PL',\n",
    "                    'L2TG', 'L2CH', 'L2FC', 'L2PL',\n",
    "                    'L3TG', 'L3CH', 'L3FC', 'L3PL',\n",
    "                    'L4TG', 'L4CH', 'L4FC', 'L4PL',\n",
    "                    'L5TG', 'L5CH', 'L5FC', 'L5PL',\n",
    "                    'L6TG', 'L6CH', 'L6FC', 'L6PL',\n",
    "\n",
    "                    'H1TG', 'H1CH', 'H1FC', 'H1PL', 'H1A1', 'H1A2',\n",
    "                    'H2TG', 'H2CH', 'H2FC', 'H2PL', 'H2A1', 'H2A2',\n",
    "                    'H3TG', 'H3CH', 'H3FC', 'H3PL', 'H3A1', 'H3A2',\n",
    "                    'H4TG', 'H4CH', 'H4FC', 'H4PL', 'H4A1', 'H4A2',\n",
    "        \n",
    "                    'TPTG', 'TPCH', 'TPA1', 'TPA2', 'TPAB',        \n",
    "                    'VLCH', 'LDCH', 'HDCH',  \n",
    "                    'VLTG', 'LDTG', 'HDTG',  \n",
    "                    'VLFC', 'LDFC', 'HDFC', \n",
    "                    'VLPL', 'LDPL', 'HDPL', 'HDA1', 'HDA2', \n",
    "                    'VLAB', 'IDAB', 'LDAB', \n",
    "                    'L1AB', 'L2AB', 'L3AB', 'L4AB', 'L5AB', 'L6AB'\n",
    "                    ]\n",
    "\n",
    "\n",
    "    # Create a concatenated list of RGB values to assign vars_MB_order colors \n",
    "    # NOTE 1 : use * operator for list concatenation and *n for repeation\n",
    "    # NOTE 2 : the indexes of the DF (variables) )were reorganized before based on vars_LP_order list\n",
    "    vars_color = [*[[.6,.1,.0]]*4 , *[[.7,.2,.0]]*4 , *[[.8,.3,.0]]*4 , *[[.9,.4,.0]]*4, *[[1 ,.5,.0]]*4,\n",
    "                  *[[.2,.8,.2]]*4 , \n",
    "                  *[[.7,.7,.0]]*4 , *[[.8,.8,.0]]*4 , *[[.9,.9,.0]]*4 , \n",
    "                  *[[1.,.7,.0]]*4 , *[[1.,.8,.0]]*4 , *[[1.,.9,.0]]*4 ,\n",
    "                  *[[.1,.3,.8]]*6 , *[[.1,.4,.9]]*6 , *[[.1,.5,1.]]*6 , *[[.1,.6,1.]]*6,\n",
    "                  *[[.8,.9,.8]]*5 ,\n",
    "                  *[[.7,.6,.6]]*23 \n",
    "    ]   \n",
    "    \n",
    "    \n",
    "elif data_type == \"MB\":    \n",
    "    vars_order = [  \n",
    "                    'Lysine', 'Histidine', 'Glutamic acid',\n",
    "                    'Glutamine', 'Asparagine', 'Threonine', \n",
    "                    'Glycine', 'Proline',\n",
    "                    'Phenylalanine', 'Leucine', 'Alanine', 'Tyrosine', 'Valine', 'Isoleucine', 'Methionine',                  \n",
    "                    'N,N-Dimethylglycine', 'Ornithine', 'Sarcosine',                 \n",
    "                    '2-Hydroxybutyric acid', '3-Hydroxybutyric acid', '2-Oxoglutaric acid', '2-Aminobutyric acid',\n",
    "                    'Pyruvic acid', 'Citric acid', 'Acetic acid', 'Lactic acid', 'Succinic acid', 'Formic acid', 'Acetoacetic acid',                  \n",
    "                    'K-EDTA','Ca-EDTA',                 \n",
    "                    'Acetone', 'Glycerol',                 \n",
    "                    'D-Galactose', 'Glucose',                 \n",
    "                    'Dimethylsulfone',                   \n",
    "                    'Choline', 'Creatine', 'Creatinine'\n",
    "                 ]\n",
    "    # Create a concatenated list of RGB values to assign vars_MB_order colors \n",
    "    # NOTE 1 : use * operator for list concatenation and *n for repeation\n",
    "    # NOTE 2 : the indexes of the DF (variables) )were reorganized before based on vars_MB_order list\n",
    "    vars_color = [*[[0,0.6,1]]*3 , *[[0, 0.4, 1]]*3 , *[[0, 0.2, 1]]*2 , *[[0, 0, 1]]*7,\n",
    "                  *[[1,0.8,0.2]]*3 , \n",
    "                  *[[1,0.4,0.2]]*4 , \n",
    "                  *[[1,0.0,0.2]]*7 , \n",
    "                  *[[0.2, 0.5, 0.2]]*2 , *[[0.1, 0.6, 0.1]]*2 , *[[0.0, 0.6, 0.0]]*2 , *[[.8, .8, 0]]*1, *[[0, 0.7, 0.2]]*3 ] \n",
    "\n",
    "\"\"\"\n",
    "R = []\n",
    "G = []\n",
    "B = []\n",
    "for xx in vars_color:\n",
    "    R.append( xx[0] )\n",
    "    G.append( xx[1] )\n",
    "    B.append( xx[2] )\n",
    "\n",
    "tableVars_Order_RGB = pd.DataFrame(data = np.array([vars_order, R, G, B]).T, columns = [\"LP_names\", \"R\", \"G\", \"B\"])\n",
    "tableVars_Order_RGB\n",
    "# --_ SAVE --- Save as Python-Ready .csv file\n",
    "tableVars_Order_RGB.to_csv( root_path + \"/table\"+data_type+\"_Order_RGB.csv\", header=True, index=False)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
